{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Optimizing VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following goes through the process of fine-tuning a pre-existing VGG19 convolution neural network using the CIFAR10 dataset, then optimizing using pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import VGG19 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Pre-process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CIFAR10(\n",
    "    root=\"./CIFAR10-Train\",\n",
    "    train=True,\n",
    "    transform=preprocess,\n",
    "    target_transform=None,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CIFAR10(\n",
    "    root=\"./CIFAR10-Test\",\n",
    "    train=False,\n",
    "    transform=preprocess,\n",
    "    target_transform=None,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset and show stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to split data\n",
    "split_index = int(len(test_data) / 2)\n",
    "\n",
    "split_size = len(test_data) // 2\n",
    "test_set, val_set = random_split(test_data, [split_size, len(test_data) - split_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Stats on CIFA100 Dataset\n",
      "------------------------\n",
      "Train Dataset Size: 50000\n",
      "Train - Number of Unique Targets: 10\n",
      "\n",
      "Test Dataset Size: 5000\n",
      "Test - Number of Unique Targets: 10\n",
      "\n",
      "Val Dataset Size: 5000\n",
      "Val - Number of Unique Targets: 10\n"
     ]
    }
   ],
   "source": [
    "print('------------------------')\n",
    "print('Stats on CIFA100 Dataset')\n",
    "print('------------------------')\n",
    "print(f'Train Dataset Size: {len(train_data)}')\n",
    "print(f'Train - Number of Unique Targets: {len(train_data.classes)}')\n",
    "print('')\n",
    "print(f'Test Dataset Size: {len(test_set)}')\n",
    "print(f'Test - Number of Unique Targets: {len(test_set.dataset.classes)}')\n",
    "print('')\n",
    "print(f'Val Dataset Size: {len(val_set)}')\n",
    "print(f'Val - Number of Unique Targets: {len(val_set.dataset.classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and update model for classifier size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Convert model's predefined output classifier to new classifier that has our actual number of classes\n",
    "# Layer 6 is the classifier layer\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use CrossEntropyLoss for classification loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Calculation (F1, Recall, Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(classes, df:pd.DataFrame):\n",
    "    df_copy = df.copy()\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in classes:\n",
    "        true_positives += len(df_copy[(df_copy['y_true'] == i) & (df_copy['y_pred'] == i)])\n",
    "        false_negatives += len(df_copy[(df_copy['y_true'] == i) & (df_copy['y_pred'] != i)])\n",
    "        false_positives += len(df_copy[(df_copy['y_true'] != i) & (df_copy['y_pred'] == i)])\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Put back to CPU and put in proper format\n",
    "        labels_cpu = labels.cpu().numpy()\n",
    "        predicted_cpu = predicted.cpu().numpy()\n",
    "        \n",
    "        batch_df = pd.DataFrame({\n",
    "            'y_true': labels_cpu, \n",
    "            'y_pred': predicted_cpu\n",
    "        })\n",
    "        \n",
    "        pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "        \n",
    "    classes_num = range(1, len(train_data.classes) + 1)\n",
    "    precision, recall, f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Put back to CPU and put in proper format\n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            predicted_cpu = predicted.cpu().numpy()\n",
    "            \n",
    "            batch_df = pd.DataFrame({\n",
    "                'y_true': labels_cpu, \n",
    "                'y_pred': predicted_cpu\n",
    "            })\n",
    "            \n",
    "            pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "            \n",
    "    classes_num = range(1, len(train_data.classes) + 1)\n",
    "    precision, recall, f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "# Create lists to store metrics for each epoch\n",
    "training_history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'train_precision': [],\n",
    "    'train_recall': [],\n",
    "    'train_f1': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Training phase \n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validation phase \n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Store metrics in history dictionary\n",
    "    training_history['epoch'].append(epoch + 1)\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['train_acc'].append(train_acc)\n",
    "    training_history['train_precision'].append(train_precision)\n",
    "    training_history['train_recall'].append(train_recall)\n",
    "    training_history['train_f1'].append(train_f1)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['val_acc'].append(val_acc)\n",
    "    training_history['val_precision'].append(val_precision)\n",
    "    training_history['val_recall'].append(val_recall)\n",
    "    training_history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print training metrics\n",
    "    print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}%')\n",
    "    print(f'Train Precision: {train_precision:.4f} Recall: {train_recall:.4f} F1: {train_f1:.4f}')\n",
    "    \n",
    "    # Print validation metrics\n",
    "    print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%')\n",
    "    print(f'Val Precision: {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Update best accuracy if current validation accuracy is better\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        print(f'New best validation accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Print final best accuracy\n",
    "print(f'Training completed - Best validation accuracy: {best_acc:.2f}%')\n",
    "\n",
    "# Create DataFrame from training history\n",
    "training_df = pd.DataFrame(training_history)\n",
    "\n",
    "# Export to CSV file\n",
    "training_df.to_csv('./Training_Outputs/CIFAR10/training_history_CIFAR10.csv', index=False)\n",
    "torch.save(model.state_dict(), './Training_Outputs/CIFAR10/CIFAR10_VGG19_Model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module1-ece438",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
