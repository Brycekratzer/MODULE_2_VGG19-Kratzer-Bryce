{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Optimizing VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following goes through the process of fine-tuning a pre-existing VGG19 convolution neural network using the CIFAR10 dataset, then optimizing using pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import VGG19 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Pre-process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:05<00:00, 33.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(\n",
    "    root=\"./CIFAR10-Train\",\n",
    "    train=True,\n",
    "    transform=preprocess,\n",
    "    target_transform=None,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:04<00:00, 34.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "test_data = CIFAR10(\n",
    "    root=\"./CIFAR10-Test\",\n",
    "    train=False,\n",
    "    transform=preprocess,\n",
    "    target_transform=None,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset and show stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index to split data\n",
    "split_index = int(len(test_data) / 2)\n",
    "\n",
    "split_size = len(test_data) // 2\n",
    "test_set, val_set = random_split(test_data, [split_size, len(test_data) - split_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Stats on CIFA100 Dataset\n",
      "------------------------\n",
      "Train Dataset Size: 50000\n",
      "Train - Number of Unique Targets: 10\n",
      "\n",
      "Test Dataset Size: 5000\n",
      "Test - Number of Unique Targets: 10\n",
      "\n",
      "Val Dataset Size: 5000\n",
      "Val - Number of Unique Targets: 10\n"
     ]
    }
   ],
   "source": [
    "print('------------------------')\n",
    "print('Stats on CIFA100 Dataset')\n",
    "print('------------------------')\n",
    "print(f'Train Dataset Size: {len(train_data)}')\n",
    "print(f'Train - Number of Unique Targets: {len(train_data.classes)}')\n",
    "print('')\n",
    "print(f'Test Dataset Size: {len(test_set)}')\n",
    "print(f'Test - Number of Unique Targets: {len(test_set.dataset.classes)}')\n",
    "print('')\n",
    "print(f'Val Dataset Size: {len(val_set)}')\n",
    "print(f'Val - Number of Unique Targets: {len(val_set.dataset.classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and update model for classifier size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Convert model's predefined output classifier to new classifier that has our actual number of classes\n",
    "# Layer 6 is the classifier layer\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use CrossEntropyLoss for classification loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Calculation (F1, Recall, Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(classes, df:pd.DataFrame):\n",
    "    df_copy = df.copy()\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i in classes:\n",
    "        true_positives += len(df_copy[(df_copy['y_true'] == i) & (df_copy['y_pred'] == i)])\n",
    "        false_negatives += len(df_copy[(df_copy['y_true'] == i) & (df_copy['y_pred'] != i)])\n",
    "        false_positives += len(df_copy[(df_copy['y_true'] != i) & (df_copy['y_pred'] == i)])\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Put back to CPU and put in proper format\n",
    "        labels_cpu = labels.cpu().numpy()\n",
    "        predicted_cpu = predicted.cpu().numpy()\n",
    "        \n",
    "        batch_df = pd.DataFrame({\n",
    "            'y_true': labels_cpu, \n",
    "            'y_pred': predicted_cpu\n",
    "        })\n",
    "        \n",
    "        pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "        \n",
    "    classes_num = range(len(train_data.classes))\n",
    "    precision, recall, f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Put back to CPU and put in proper format\n",
    "            labels_cpu = labels.cpu().numpy()\n",
    "            predicted_cpu = predicted.cpu().numpy()\n",
    "            \n",
    "            batch_df = pd.DataFrame({\n",
    "                'y_true': labels_cpu, \n",
    "                'y_pred': predicted_cpu\n",
    "            })\n",
    "            \n",
    "            pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "            \n",
    "    classes_num = range(len(train_data.classes))\n",
    "    precision, recall, f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1563 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:23<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:10<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4924 Acc: 83.36%\n",
      "Train Precision: 0.8336 Recall: 0.8336 F1: 0.8336\n",
      "Val Loss: 0.3136 Acc: 89.36%\n",
      "Val Precision: 0.8936 Recall: 0.8936 F1: 0.8936\n",
      "New best validation accuracy: 89.36%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:20<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:08<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2615 Acc: 91.24%\n",
      "Train Precision: 0.9124 Recall: 0.9124 F1: 0.9124\n",
      "Val Loss: 0.2916 Acc: 90.38%\n",
      "Val Precision: 0.9038 Recall: 0.9038 F1: 0.9038\n",
      "New best validation accuracy: 90.38%\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:23<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1911 Acc: 93.54%\n",
      "Train Precision: 0.9354 Recall: 0.9354 F1: 0.9354\n",
      "Val Loss: 0.3227 Acc: 89.58%\n",
      "Val Precision: 0.8958 Recall: 0.8958 F1: 0.8958\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:22<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1476 Acc: 95.09%\n",
      "Train Precision: 0.9509 Recall: 0.9509 F1: 0.9509\n",
      "Val Loss: 0.3270 Acc: 90.36%\n",
      "Val Precision: 0.9036 Recall: 0.9036 F1: 0.9036\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:17<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:08<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1153 Acc: 96.21%\n",
      "Train Precision: 0.9621 Recall: 0.9621 F1: 0.9621\n",
      "Val Loss: 0.3020 Acc: 91.00%\n",
      "Val Precision: 0.9100 Recall: 0.9100 F1: 0.9100\n",
      "New best validation accuracy: 91.00%\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:19<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0984 Acc: 96.84%\n",
      "Train Precision: 0.9684 Recall: 0.9684 F1: 0.9684\n",
      "Val Loss: 0.3337 Acc: 90.72%\n",
      "Val Precision: 0.9072 Recall: 0.9072 F1: 0.9072\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:16<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0848 Acc: 97.25%\n",
      "Train Precision: 0.9725 Recall: 0.9725 F1: 0.9725\n",
      "Val Loss: 0.2841 Acc: 92.08%\n",
      "Val Precision: 0.9208 Recall: 0.9208 F1: 0.9208\n",
      "New best validation accuracy: 92.08%\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:18<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:08<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0770 Acc: 97.52%\n",
      "Train Precision: 0.9752 Recall: 0.9752 F1: 0.9752\n",
      "Val Loss: 0.3301 Acc: 91.38%\n",
      "Val Precision: 0.9138 Recall: 0.9138 F1: 0.9138\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:17<00:00,  1.09s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0695 Acc: 97.77%\n",
      "Train Precision: 0.9777 Recall: 0.9777 F1: 0.9777\n",
      "Val Loss: 0.4218 Acc: 89.64%\n",
      "Val Precision: 0.8964 Recall: 0.8964 F1: 0.8964\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [28:14<00:00,  1.08s/it]\n",
      "100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0657 Acc: 97.90%\n",
      "Train Precision: 0.9790 Recall: 0.9790 F1: 0.9790\n",
      "Val Loss: 0.3883 Acc: 90.92%\n",
      "Val Precision: 0.9092 Recall: 0.9092 F1: 0.9092\n",
      "\n",
      "Training completed - Best validation accuracy: 92.08%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "\n",
    "# Create lists to store metrics for each epoch\n",
    "training_history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'train_precision': [],\n",
    "    'train_recall': [],\n",
    "    'train_f1': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'val_precision': [],\n",
    "    'val_recall': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Training phase \n",
    "    train_loss, train_acc, train_precision, train_recall, train_f1 = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validation phase \n",
    "    val_loss, val_acc, val_precision, val_recall, val_f1 = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Store metrics in history dictionary\n",
    "    training_history['epoch'].append(epoch + 1)\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['train_acc'].append(train_acc)\n",
    "    training_history['train_precision'].append(train_precision)\n",
    "    training_history['train_recall'].append(train_recall)\n",
    "    training_history['train_f1'].append(train_f1)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    training_history['val_acc'].append(val_acc)\n",
    "    training_history['val_precision'].append(val_precision)\n",
    "    training_history['val_recall'].append(val_recall)\n",
    "    training_history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print training metrics\n",
    "    print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}%')\n",
    "    print(f'Train Precision: {train_precision:.4f} Recall: {train_recall:.4f} F1: {train_f1:.4f}')\n",
    "    \n",
    "    # Print validation metrics\n",
    "    print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%')\n",
    "    print(f'Val Precision: {val_precision:.4f} Recall: {val_recall:.4f} F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Update best accuracy if current validation accuracy is better\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        print(f'New best validation accuracy: {best_acc:.2f}%')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Print final best accuracy\n",
    "print(f'Training completed - Best validation accuracy: {best_acc:.2f}%')\n",
    "\n",
    "# Create DataFrame from training history\n",
    "training_df = pd.DataFrame(training_history)\n",
    "\n",
    "# Export to CSV file\n",
    "training_df.to_csv('./training_history_CIFAR10.csv', index=False)\n",
    "torch.save(model.state_dict(), './CIFAR10_VGG19_Model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the model architecture\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "# Modify final layer if needed for your classes\n",
    "model.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
    "\n",
    "# Load the state dict\n",
    "model.load_state_dict(torch.load('./VGG19_Models/Trained_Model/CIFAR10_VGG19_Model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (No Pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:03<00:00, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 12.5724 Acc: 90.42%\n",
      "Test Precision: 0.9009 Recall: 0.9015 F1: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "testing_metrics = {\n",
    "    'test_loss': [],\n",
    "    'test_acc': [],\n",
    "    'test_precision': [],\n",
    "    'test_recall': [],\n",
    "    'test_f1': [],\n",
    "    'latency': [],\n",
    "    'throughput': [],\n",
    "}\n",
    "\n",
    "latency_times = []\n",
    "loop_start = time.perf_counter()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_set):\n",
    "        \n",
    "        # Convert Inputs and Outputs to proper format for model\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        labels = torch.tensor([labels])\n",
    "        \n",
    "        # Get model prediction and total inference time\n",
    "        inference_start = time.perf_counter()\n",
    "        outputs = model(inputs)\n",
    "        inference_end = time.perf_counter()\n",
    "        latency_times.append(inference_end - inference_start)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Tally Model Metrics - Loss, Prediction vs Correct values\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        batch_df = pd.DataFrame({\n",
    "            'y_true': labels, \n",
    "            'y_pred': predicted\n",
    "        })\n",
    "        \n",
    "        pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "\n",
    "    loop_end = time.perf_counter()\n",
    "    \n",
    "# Calculate Hardware Metrics - Latency and Throughput\n",
    "avg_latency = np.mean(latency_times)\n",
    "throughput = total / (loop_end - loop_start)\n",
    "\n",
    "# Calculate Test Precision, Recall, F1\n",
    "classes_num = range(1, len(train_data.classes) + 1)\n",
    "test_precision, test_recall, test_f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "\n",
    "# Calculate Basic Model Metrics  - Loss and Accuracy\n",
    "test_loss = running_loss / len(val_loader)\n",
    "test_acc = 100. * correct / total\n",
    "\n",
    "# Add Metrics to Dictionary\n",
    "testing_metrics['test_loss'].append(test_loss)\n",
    "testing_metrics['test_acc'].append(test_acc)\n",
    "testing_metrics['test_precision'].append(test_precision)\n",
    "testing_metrics['test_recall'].append(test_recall)\n",
    "testing_metrics['test_f1'].append(test_f1)\n",
    "testing_metrics['latency'].append(avg_latency)\n",
    "testing_metrics['throughput'].append(throughput)\n",
    "testing_metrics = pd.DataFrame(testing_metrics)\n",
    "\n",
    "# Print testing metrics\n",
    "print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.2f}%')\n",
    "print(f'Test Precision: {test_precision:.4f} Recall: {test_recall:.4f} F1: {test_f1:.4f}')\n",
    "testing_metrics.to_csv('./test_history_NO_PRUNE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (With Structured Pruning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning is a way to remove \"insignificant\" weights in a trained model. In return, this leads to quicker inference times due to less computation (fewer MAC operations).\n",
    "\n",
    "The pruning method used will be an unstructured approach. The unstructured approach removes single weigths of filters from a convolutional neural network, which VGG19 utilizes. This removal of single weights allows for easier model acceleration on hardware (compared to unstructured pruning, which creates irregular sparsity patterns), which is our reason for pruning.\n",
    "\n",
    "Earlier layers in VGG19 are more sensitive to pruning, as they capture fundamental low-level features like edges, textures, and basic shapes. Later layers are less sensitive as they learn more abstract, high-level features that often have more redundancy. So we will use a low percentage of pruning for the first couple layers and increase the percentage as we proceed downstream in the VGG19 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "def prune_model(model, initial_prune_percent, max_prune_percent, increment_percent, percent_rate_change):\n",
    "    i = 0\n",
    "    for feat in model.features:\n",
    "        if str(feat).startswith('Conv2d'):\n",
    "            i += 1 # Tracks which conv2d layer we are at\n",
    "            if(i % percent_rate_change == 0):\n",
    "                if initial_prune_percent < max_prune_percent:\n",
    "                    initial_prune_percent +=  increment_percent\n",
    "                initial_prune_percent = round(initial_prune_percent, 2)\n",
    "            \n",
    "            # Structured Pruning based on L1 normalization\n",
    "            prune.l1_unstructured(\n",
    "                feat,\n",
    "                name=\"weight\",\n",
    "                amount=initial_prune_percent,\n",
    "            )\n",
    "            prune.remove(feat, \"weight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pruning = {\n",
    "    'setting_type': 'low',\n",
    "    'init_perc': .05,       # Initial Pruning Percentage\n",
    "    'max_perc': .5,         # Max Pruning Percentage\n",
    "    'increment_perc': .05,  # How much to increase pruning by\n",
    "    'perc_rate': 3          # How often to increase pruning by\n",
    "}\n",
    "\n",
    "medium_pruning = {\n",
    "    'setting_type': 'medium',\n",
    "    'init_perc': .1,\n",
    "    'max_perc': .7,\n",
    "    'increment_perc': .15,\n",
    "    'perc_rate': 3\n",
    "}\n",
    "\n",
    "high_pruning = {\n",
    "    'setting_type': 'high',\n",
    "    'init_perc': .2,\n",
    "    'max_perc': .8,\n",
    "    'increment_perc': .15,\n",
    "    'perc_rate': 3\n",
    "}\n",
    "\n",
    "prune_settings = [low_pruning, medium_pruning, high_pruning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 5000/5000 [05:58<00:00, 13.93it/s]\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 12.4355 Acc: 90.26%\n",
      "Test Precision: 0.9002 Recall: 0.8992 F1: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:05<00:00, 13.67it/s]\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/module1-ece438/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 17.2473 Acc: 86.36%\n",
      "Test Precision: 0.8571 Recall: 0.8601 F1: 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [05:46<00:00, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 38.8586 Acc: 73.88%\n",
      "Test Precision: 0.7207 Recall: 0.7324 F1: 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "for setting in prune_settings:\n",
    "    # Recreate the model architecture\n",
    "    model = models.vgg19(pretrained=True)\n",
    "\n",
    "    # Modify final layer if needed for your classes\n",
    "    model.classifier[6] = torch.nn.Linear(4096, num_classes)\n",
    "\n",
    "    # Load the state dict\n",
    "    model.load_state_dict(torch.load('../VGG19_Models/Trained_Model/CIFAR10_VGG19_Model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    prune_model(\n",
    "        model, \n",
    "        setting['init_perc'], \n",
    "        setting['max_perc'], \n",
    "        setting['increment_perc'],\n",
    "        setting['perc_rate']\n",
    "    )\n",
    "    \n",
    "    pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    testing_metrics = {\n",
    "        'test_loss': [],\n",
    "        'test_acc': [],\n",
    "        'test_precision': [],\n",
    "        'test_recall': [],\n",
    "        'test_f1': [],\n",
    "        'latency': [],\n",
    "        'throughput': [],\n",
    "        'inital_prune':[],\n",
    "        'max_prune_perc':[],\n",
    "        'increment_by': [],\n",
    "        'rate_of_increase':[]\n",
    "    }\n",
    "\n",
    "    latency_times = []\n",
    "    loop_start = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_set):\n",
    "            \n",
    "            # Convert Inputs and Outputs to proper format for model\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            labels = torch.tensor([labels])\n",
    "            \n",
    "            # Get model prediction and total inference time\n",
    "            inference_start = time.perf_counter()\n",
    "            outputs = model(inputs)\n",
    "            inference_end = time.perf_counter()\n",
    "            latency_times.append(inference_end - inference_start)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Tally Model Metrics - Loss, Prediction vs Correct values\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            batch_df = pd.DataFrame({\n",
    "                'y_true': labels, \n",
    "                'y_pred': predicted\n",
    "            })\n",
    "            \n",
    "            pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "\n",
    "        loop_end = time.perf_counter()\n",
    "        \n",
    "    # Calculate Hardware Metrics - Latency and Throughput\n",
    "    avg_latency = np.mean(latency_times)\n",
    "    throughput = total / (loop_end - loop_start)\n",
    "\n",
    "    # Calculate Test Precision, Recall, F1\n",
    "    classes_num = range(1, len(train_data.classes) + 1)\n",
    "    test_precision, test_recall, test_f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "\n",
    "    # Calculate Basic Model Metrics  - Loss and Accuracy\n",
    "    test_loss = running_loss / len(val_loader)\n",
    "    test_acc = 100. * correct / total\n",
    "\n",
    "    # Add Metrics to Dictionary\n",
    "    testing_metrics['test_loss'].append(test_loss)\n",
    "    testing_metrics['test_acc'].append(test_acc)\n",
    "    testing_metrics['test_precision'].append(test_precision)\n",
    "    testing_metrics['test_recall'].append(test_recall)\n",
    "    testing_metrics['test_f1'].append(test_f1)\n",
    "    testing_metrics['latency'].append(avg_latency)\n",
    "    testing_metrics['throughput'].append(throughput)\n",
    "    testing_metrics['inital_prune'].append(setting['init_perc'])\n",
    "    testing_metrics['max_prune_perc'].append(setting['max_perc'])\n",
    "    testing_metrics['increment_by'].append(setting['increment_perc'])\n",
    "    testing_metrics['rate_of_increase'].append(setting['perc_rate'])\n",
    "    testing_metrics = pd.DataFrame(testing_metrics)\n",
    "\n",
    "    # Print testing metrics\n",
    "    print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.2f}%')\n",
    "    print(f'Test Precision: {test_precision:.4f} Recall: {test_recall:.4f} F1: {test_f1:.4f}')\n",
    "    string = f\"./test_history_unstructured_prune_{setting['setting_type']}_setting.csv\"\n",
    "    testing_metrics.to_csv(string, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 0                \n",
    "initial_perc = .1    \n",
    "max_perc = .7        \n",
    "increment_perc = .1  \n",
    "perc_adjust_rate = 3 \n",
    "\n",
    "for feat in model.features:\n",
    "    if str(feat).startswith('Conv2d'):\n",
    "        i += 1 # Tracks which conv2d layer we are at\n",
    "        if(i % perc_adjust_rate == 0):\n",
    "            if initial_perc < max_perc:\n",
    "                initial_perc +=  increment_perc\n",
    "            initial_perc = round(initial_perc, 2)\n",
    "        \n",
    "        # Structured Pruning based on L1 normalization\n",
    "        prune.l1_unstructured(\n",
    "            feat,\n",
    "            name=\"weight\",\n",
    "            amount=initial_perc,\n",
    "        )\n",
    "        prune.remove(feat, \"weight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing (With Structured Pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [05:52<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 148.5001 Acc: 30.72%\n",
      "Test Precision: 0.2879 Recall: 0.3102 F1: 0.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pred_v_true = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "testing_metrics = {\n",
    "    'test_loss': [],\n",
    "    'test_acc': [],\n",
    "    'test_precision': [],\n",
    "    'test_recall': [],\n",
    "    'test_f1': [],\n",
    "    'latency': [],\n",
    "    'throughput': [],\n",
    "}\n",
    "\n",
    "latency_times = []\n",
    "loop_start = time.perf_counter()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_set):\n",
    "        \n",
    "        # Convert Inputs and Outputs to proper format for model\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        labels = torch.tensor([labels])\n",
    "        \n",
    "        # Get model prediction and total inference time\n",
    "        inference_start = time.perf_counter()\n",
    "        outputs = model(inputs)\n",
    "        inference_end = time.perf_counter()\n",
    "        latency_times.append(inference_end - inference_start)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Tally Model Metrics - Loss, Prediction vs Correct values\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        batch_df = pd.DataFrame({\n",
    "            'y_true': labels, \n",
    "            'y_pred': predicted\n",
    "        })\n",
    "        \n",
    "        pred_v_true = pd.concat([pred_v_true, batch_df], ignore_index=True)\n",
    "\n",
    "    loop_end = time.perf_counter()\n",
    "    \n",
    "# Calculate Hardware Metrics - Latency and Throughput\n",
    "avg_latency = np.mean(latency_times)\n",
    "throughput = total / (loop_end - loop_start)\n",
    "\n",
    "# Calculate Test Precision, Recall, F1\n",
    "classes_num = range(1, len(train_data.classes) + 1)\n",
    "test_precision, test_recall, test_f1 = calculate_metrics(classes_num, pred_v_true)\n",
    "\n",
    "# Calculate Basic Model Metrics  - Loss and Accuracy\n",
    "test_loss = running_loss / len(val_loader)\n",
    "test_acc = 100. * correct / total\n",
    "\n",
    "# Add Metrics to Dictionary\n",
    "testing_metrics['test_loss'].append(test_loss)\n",
    "testing_metrics['test_acc'].append(test_acc)\n",
    "testing_metrics['test_precision'].append(test_precision)\n",
    "testing_metrics['test_recall'].append(test_recall)\n",
    "testing_metrics['test_f1'].append(test_f1)\n",
    "testing_metrics['latency'].append(avg_latency)\n",
    "testing_metrics['throughput'].append(throughput)\n",
    "testing_metrics = pd.DataFrame(testing_metrics)\n",
    "\n",
    "# Print testing metrics\n",
    "print(f'Test Loss: {test_loss:.4f} Acc: {test_acc:.2f}%')\n",
    "print(f'Test Precision: {test_precision:.4f} Recall: {test_recall:.4f} F1: {test_f1:.4f}')\n",
    "testing_metrics.to_csv('./test_history_unstructured_PRUNE_High_Settings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Low Settings**\n",
    "- i = 0               \n",
    "- initial_perc = .1   \n",
    "- max_perc = .7        \n",
    "- increment_perc = .1\n",
    "- perc_adjust_rate = 3 \n",
    "\n",
    "**High Setting**\n",
    "- i = 0               \n",
    "- initial_perc = .2   \n",
    "- max_perc = .7        \n",
    "- increment_perc = .2\n",
    "- perc_adjust_rate = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module1-ece438",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
